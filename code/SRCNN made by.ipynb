{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def create_low_res_images(input_dir, output_dir, scale):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "            img = Image.open(os.path.join(input_dir, filename))\n",
    "            # 고해상도에서 저해상도 이미지 생성\n",
    "            lr_img = img.resize((img.width // scale, img.height // scale), Image.BICUBIC)\n",
    "            # 생성된 저해상도 이미지를 저장\n",
    "            lr_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "# 경로 설정\n",
    "train_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_HR\"\n",
    "valid_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_HR\"\n",
    "\n",
    "train_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_LR\"\n",
    "valid_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_LR\"\n",
    "\n",
    "# 배율 설정 (예: ×2)\n",
    "scale = 2\n",
    "\n",
    "# 저해상도 이미지 생성\n",
    "create_low_res_images(train_hr_dir, train_lr_dir, scale)\n",
    "create_low_res_images(valid_hr_dir, valid_lr_dir, scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, hr_dir, lr_dir, transform=None):\n",
    "        self.hr_dir = hr_dir\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_filenames = sorted(os.listdir(hr_dir))\n",
    "        self.lr_filenames = sorted(os.listdir(lr_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hr_path = os.path.join(self.hr_dir, self.hr_filenames[idx])\n",
    "        lr_path = os.path.join(self.lr_dir, self.lr_filenames[idx])\n",
    "\n",
    "        hr_img = Image.open(hr_path)\n",
    "        lr_img = Image.open(lr_path)\n",
    "\n",
    "        if self.transform:\n",
    "            hr_img = self.transform(hr_img)\n",
    "            lr_img = self.transform(lr_img)\n",
    "\n",
    "        return lr_img, hr_img\n",
    "\n",
    "# 데이터 경로\n",
    "train_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_HR\"\n",
    "train_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_LR\"\n",
    "valid_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_HR\"\n",
    "valid_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_LR\"\n",
    "\n",
    "# 데이터 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Tensor로 변환\n",
    "])\n",
    "\n",
    "# Dataset 및 DataLoader\n",
    "train_dataset = SRDataset(train_hr_dir, train_lr_dir, transform)\n",
    "valid_dataset = SRDataset(valid_hr_dir, valid_lr_dir, transform)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, hr_dir, lr_dir, transform=None):\n",
    "        self.hr_dir = hr_dir\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_filenames = sorted(os.listdir(hr_dir))\n",
    "        self.lr_filenames = sorted(os.listdir(lr_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hr_path = os.path.join(self.hr_dir, self.hr_filenames[idx])\n",
    "        lr_path = os.path.join(self.lr_dir, self.lr_filenames[idx])\n",
    "\n",
    "        hr_img = Image.open(hr_path)\n",
    "        lr_img = Image.open(lr_path)\n",
    "\n",
    "        if self.transform:\n",
    "            hr_img = self.transform(hr_img)\n",
    "            lr_img = self.transform(lr_img)\n",
    "\n",
    "        return lr_img, hr_img\n",
    "\n",
    "# 데이터 경로\n",
    "train_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_HR\"\n",
    "train_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_LR\"\n",
    "valid_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_HR\"\n",
    "valid_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_LR\"\n",
    "\n",
    "# 데이터 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Tensor로 변환\n",
    "])\n",
    "\n",
    "# Dataset 및 DataLoader\n",
    "train_dataset = SRDataset(train_hr_dir, train_lr_dir, transform)\n",
    "valid_dataset = SRDataset(valid_hr_dir, valid_lr_dir, transform)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# 1. SRDataset 클래스 정의\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, hr_dir, lr_dir, transform=None, target_size=(256, 256)):\n",
    "        \"\"\"\n",
    "        고해상도(HR) 및 저해상도(LR) 이미지 데이터셋.\n",
    "\n",
    "        Args:\n",
    "            hr_dir (str): 고해상도 이미지 경로.\n",
    "            lr_dir (str): 저해상도 이미지 경로.\n",
    "            transform (callable, optional): 이미지에 적용할 변환 함수.\n",
    "            target_size (tuple, optional): 리사이즈할 목표 크기.\n",
    "        \"\"\"\n",
    "        self.hr_dir = hr_dir\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_filenames = sorted(os.listdir(hr_dir))\n",
    "        self.lr_filenames = sorted(os.listdir(lr_dir))\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size  # 고정 크기\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hr_path = os.path.join(self.hr_dir, self.hr_filenames[idx])\n",
    "        lr_path = os.path.join(self.lr_dir, self.lr_filenames[idx])\n",
    "\n",
    "        hr_img = Image.open(hr_path).convert(\"RGB\")\n",
    "        lr_img = Image.open(lr_path).convert(\"RGB\")\n",
    "\n",
    "        # 고정 크기로 리사이즈\n",
    "        hr_img = F.resize(hr_img, self.target_size)\n",
    "        lr_img = F.resize(lr_img, self.target_size)\n",
    "\n",
    "        if self.transform:\n",
    "            hr_img = self.transform(hr_img)\n",
    "            lr_img = self.transform(lr_img)\n",
    "\n",
    "        return lr_img, hr_img\n",
    "\n",
    "\n",
    "# 2. 모델 정의 (SRCNN 예제)\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 3. 데이터 경로 설정\n",
    "train_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_HR\"\n",
    "train_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_LR\"\n",
    "valid_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_HR\"\n",
    "valid_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_LR\"\n",
    "\n",
    "# 데이터 변환 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 이미지를 Tensor로 변환\n",
    "])\n",
    "\n",
    "# Dataset 및 DataLoader 설정\n",
    "train_dataset = SRDataset(train_hr_dir, train_lr_dir, transform, target_size=(256, 256))\n",
    "valid_dataset = SRDataset(valid_hr_dir, valid_lr_dir, transform, target_size=(256, 256))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 학습 준비\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRCNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.0622\n"
     ]
    }
   ],
   "source": [
    "# 5. 학습 루프\n",
    "num_epochs = 1  # 에포크 수 설정\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for lr_imgs, hr_imgs in train_loader:\n",
    "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "\n",
    "        # 모델 예측\n",
    "        preds = model(lr_imgs)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(preds, hr_imgs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0156\n"
     ]
    }
   ],
   "source": [
    "# 6. 검증\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    valid_loss = 0\n",
    "    for lr_imgs, hr_imgs in valid_loader:\n",
    "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "        preds = model(lr_imgs)\n",
    "        loss = criterion(preds, hr_imgs)\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "    print(f\"Validation Loss: {valid_loss / len(valid_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Train Loss: 0.0042, Validation Loss: 0.0037\n",
      "Best model saved at epoch 1\n",
      "Epoch 2/2, Train Loss: 0.0027, Validation Loss: 0.0026\n",
      "Best model saved at epoch 2\n"
     ]
    }
   ],
   "source": [
    "# 최적 가중치 저장 경로와 초기값 설정\n",
    "save_path = r\"C:\\Users\\kowm6\\Desktop\\sr\\best_model.pth\"\n",
    "best_valid_loss = float('inf')  # 초기값 설정 (무한대로 초기화)\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for lr_imgs, hr_imgs in train_loader:\n",
    "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "        preds = model(lr_imgs)\n",
    "        loss = criterion(preds, hr_imgs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # 검증\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for lr_imgs, hr_imgs in valid_loader:\n",
    "            lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "            preds = model(lr_imgs)\n",
    "            loss = criterion(preds, hr_imgs)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    valid_loss /= len(valid_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss / len(train_loader):.4f}, Validation Loss: {valid_loss:.4f}\")\n",
    "\n",
    "    # 최적 가중치 저장\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Best model saved at epoch {epoch + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] 디렉터리 이름이 올바르지 않습니다: 'C:/Users/kowm6/Desktop/SRdataset/BSD100/BSD100/image_SRF_2/img_001_SRF_2_HR.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m test_hr_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/kowm6/Desktop/SRdataset/BSD100/BSD100/image_SRF_2/img_001_SRF_2_HR.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m test_lr_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/kowm6/Desktop/SRdataset/BSD100/BSD100/image_SRF_2/img_001_SRF_2_LR.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSRDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_hr_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_lr_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mSRDataset.__init__\u001b[1;34m(self, hr_dir, lr_dir, transform, target_size)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhr_dir \u001b[38;5;241m=\u001b[39m hr_dir\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_dir \u001b[38;5;241m=\u001b[39m lr_dir\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhr_filenames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhr_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_filenames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(lr_dir))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] 디렉터리 이름이 올바르지 않습니다: 'C:/Users/kowm6/Desktop/SRdataset/BSD100/BSD100/image_SRF_2/img_001_SRF_2_HR.png'"
     ]
    }
   ],
   "source": [
    "# 6. 테스트\n",
    "test_hr_dir = \"C:/Users/kowm6/Desktop/SRdataset/BSD100/BSD100/image_SRF_2/img_001_SRF_2_HR.png\"\n",
    "test_lr_dir = \"C:/Users/kowm6/Desktop/SRdataset/BSD100/BSD100/image_SRF_2/img_001_SRF_2_LR.png\"\n",
    "test_dataset = SRDataset(test_hr_dir, test_lr_dir, transform, target_size=(256, 256))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# # 모델 로드\n",
    "# model.load_state_dict(torch.load(save_path))\n",
    "# model.eval()\n",
    "\n",
    "# # PSNR과 SSIM 계산\n",
    "# total_psnr = 0\n",
    "# total_ssim = 0\n",
    "# num_images = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for lr_imgs, hr_imgs in test_loader:\n",
    "#         lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "#         preds = model(lr_imgs).cpu().numpy().squeeze().transpose(1, 2, 0)\n",
    "#         hr_imgs = hr_imgs.cpu().numpy().squeeze().transpose(1, 2, 0)\n",
    "\n",
    "#         # PSNR 및 SSIM 계산\n",
    "#         total_psnr += psnr(hr_imgs, preds, data_range=1.0)\n",
    "#         total_ssim += ssim(hr_imgs, preds, data_range=1.0, multichannel=True)\n",
    "#         num_images += 1\n",
    "\n",
    "# print(f\"Average PSNR: {total_psnr / num_images:.4f}, Average SSIM: {total_ssim / num_images:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Train Loss: 0.0545, Validation Loss: 0.0143, Train PSNR: 14.8707, Validation PSNR: 18.5539, Validation SSIM: 0.5403\n",
      "Best model saved!\n",
      "Epoch 2/2, Train Loss: 0.0094, Validation Loss: 0.0078, Train PSNR: 20.3741, Validation PSNR: 21.1631, Validation SSIM: 0.6485\n",
      "Best model saved!\n",
      "Test PSNR: 22.8266, Test SSIM: 0.7084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kowm6\\AppData\\Local\\Temp\\ipykernel_1884\\2967394493.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_path))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F  # 여기서 avg_pool2d를 사용\n",
    "\n",
    "# PSNR 계산 함수\n",
    "def calculate_psnr(img1, img2, max_val=1.0):\n",
    "    mse = torch.mean((img1 - img2) ** 2)  # MSE 직접 계산\n",
    "    if mse == 0:\n",
    "        return float('inf')  # MSE가 0이면 무한대로 반환\n",
    "    psnr = 10 * torch.log10(max_val**2 / mse)\n",
    "    return psnr\n",
    "\n",
    "# SSIM 계산 함수\n",
    "def calculate_ssim(img1, img2, max_val=1.0):\n",
    "    C1 = (0.01 * max_val) ** 2\n",
    "    C2 = (0.03 * max_val) ** 2\n",
    "\n",
    "    mu1 = F.avg_pool2d(img1, kernel_size=3, stride=1, padding=1)\n",
    "    mu2 = F.avg_pool2d(img2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.avg_pool2d(img1 * img1, kernel_size=3, stride=1, padding=1) - mu1_sq\n",
    "    sigma2_sq = F.avg_pool2d(img2 * img2, kernel_size=3, stride=1, padding=1) - mu2_sq\n",
    "    sigma12 = F.avg_pool2d(img1 * img2, kernel_size=3, stride=1, padding=1) - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()\n",
    "\n",
    "# 저해상도 이미지 생성 함수\n",
    "def create_low_res_images(input_dir, output_dir, scale):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "            img = Image.open(os.path.join(input_dir, filename))\n",
    "            lr_img = img.resize((img.width // scale, img.height // scale), Image.BICUBIC)\n",
    "            lr_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "# SRDataset 클래스 정의\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, hr_dir, lr_dir, transform=None, target_size=(256, 256)):\n",
    "        self.hr_dir = hr_dir\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_filenames = sorted(os.listdir(hr_dir))\n",
    "        self.lr_filenames = sorted(os.listdir(lr_dir))\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hr_path = os.path.join(self.hr_dir, self.hr_filenames[idx])\n",
    "        lr_path = os.path.join(self.lr_dir, self.lr_filenames[idx])\n",
    "\n",
    "        hr_img = Image.open(hr_path).convert(\"RGB\")\n",
    "        lr_img = Image.open(lr_path).convert(\"RGB\")\n",
    "        hr_img = transforms.Resize(self.target_size)(hr_img)\n",
    "        lr_img = transforms.Resize(self.target_size)(lr_img)\n",
    "\n",
    "        if self.transform:\n",
    "            hr_img = self.transform(hr_img)\n",
    "            lr_img = self.transform(lr_img)\n",
    "\n",
    "        return lr_img, hr_img\n",
    "\n",
    "# SRCNN 모델 정의\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "# 데이터 경로\n",
    "train_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_HR\"\n",
    "train_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_LR\"\n",
    "valid_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_HR\"\n",
    "valid_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_LR\"\n",
    "\n",
    "# 데이터셋 및 DataLoader 설정\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = SRDataset(train_hr_dir, train_lr_dir, transform, target_size=(256, 256))\n",
    "valid_dataset = SRDataset(valid_hr_dir, valid_lr_dir, transform, target_size=(256, 256))\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# 학습 준비\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRCNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "num_epochs = 2\n",
    "best_valid_loss = float('inf')\n",
    "save_path = r\"C:\\Users\\kowm6\\Desktop\\sr\\best_model.pth\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 학습 루프\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_psnr = 0\n",
    "    for lr_imgs, hr_imgs in train_loader:\n",
    "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "        preds = model(lr_imgs)\n",
    "        loss = criterion(preds, hr_imgs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # PSNR 계산\n",
    "        train_psnr += calculate_psnr(preds, hr_imgs)\n",
    "\n",
    "    train_psnr /= len(train_loader)\n",
    "\n",
    "    # 검증 루프\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_psnr = 0\n",
    "    valid_ssim = 0\n",
    "    with torch.no_grad():\n",
    "        for lr_imgs, hr_imgs in valid_loader:\n",
    "            lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "            preds = model(lr_imgs)\n",
    "            valid_loss += criterion(preds, hr_imgs).item()\n",
    "\n",
    "            # PSNR 및 SSIM 계산\n",
    "            valid_psnr += calculate_psnr(preds, hr_imgs)\n",
    "            valid_ssim += calculate_ssim(preds, hr_imgs)\n",
    "\n",
    "    valid_psnr /= len(valid_loader)\n",
    "    valid_ssim /= len(valid_loader)\n",
    "    valid_loss /= len(valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "          f\"Validation Loss: {valid_loss:.4f}, Train PSNR: {train_psnr:.4f}, \"\n",
    "          f\"Validation PSNR: {valid_psnr:.4f}, Validation SSIM: {valid_ssim:.4f}\")\n",
    "\n",
    "    # 최적 가중치 저장\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"Best model saved!\")\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "test_hr_dir = r\"C:/Users/kowm6/Desktop/testlr\"\n",
    "test_lr_dir = r\"C:/Users/kowm6/Desktop/testhr\"\n",
    "test_dataset = SRDataset(test_hr_dir, test_lr_dir, transform, target_size=(256, 256))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "\n",
    "test_psnr = 0\n",
    "test_ssim = 0\n",
    "num_test_images = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for lr_imgs, hr_imgs in test_loader:\n",
    "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "        preds = model(lr_imgs)\n",
    "\n",
    "        test_psnr += calculate_psnr(preds, hr_imgs)\n",
    "        test_ssim += calculate_ssim(preds, hr_imgs)\n",
    "        num_test_images += 1\n",
    "\n",
    "test_psnr /= num_test_images\n",
    "test_ssim /= num_test_images\n",
    "\n",
    "print(f\"Test PSNR: {test_psnr:.4f}, Test SSIM: {test_ssim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PSNR: 24.4085, Test SSIM: 0.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kowm6\\AppData\\Local\\Temp\\ipykernel_1884\\4035062227.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_path))\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 평가\n",
    "test_hr_dir = r\"C:/Users/kowm6/Desktop/testlr\"\n",
    "test_lr_dir = r\"C:/Users/kowm6/Desktop/testhr\"\n",
    "test_dataset = SRDataset(test_hr_dir, test_lr_dir, transform, target_size=(256, 256))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "\n",
    "test_psnr = 0\n",
    "test_ssim = 0\n",
    "num_test_images = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for lr_imgs, hr_imgs in test_loader:\n",
    "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "        preds = model(lr_imgs)\n",
    "\n",
    "        test_psnr += calculate_psnr(preds, hr_imgs)\n",
    "        test_ssim += calculate_ssim(preds, hr_imgs)\n",
    "        num_test_images += 1\n",
    "\n",
    "test_psnr /= num_test_images\n",
    "test_ssim /= num_test_images\n",
    "\n",
    "print(f\"Test PSNR: {test_psnr:.4f}, Test SSIM: {test_ssim:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (app)",
   "language": "python",
   "name": "app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
