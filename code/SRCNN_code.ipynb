{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Train Loss: 0.0574, Validation Loss: 0.0185, Train PSNR: 14.2296, Validation PSNR: 17.4362, Validation SSIM: 0.5050\n",
      "Best model saved!\n",
      "Epoch 2/2, Train Loss: 0.0113, Validation Loss: 0.0073, Train PSNR: 19.6674, Validation PSNR: 21.4736, Validation SSIM: 0.6553\n",
      "Best model saved!\n",
      "Test PSNR: 22.6087, Test SSIM: 0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kowm6\\AppData\\Local\\Temp\\ipykernel_17876\\2967394493.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_path))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F \n",
    "\n",
    "# PSNR 계산 함수\n",
    "def calculate_psnr(img1, img2, max_val=1.0):\n",
    "    mse = torch.mean((img1 - img2) ** 2) \n",
    "    if mse == 0:\n",
    "        return float('inf')  \n",
    "    psnr = 10 * torch.log10(max_val**2 / mse)\n",
    "    return psnr\n",
    "\n",
    "# SSIM 계산 함수\n",
    "def calculate_ssim(img1, img2, max_val=1.0):\n",
    "    C1 = (0.01 * max_val) ** 2\n",
    "    C2 = (0.03 * max_val) ** 2\n",
    "\n",
    "    mu1 = F.avg_pool2d(img1, kernel_size=3, stride=1, padding=1)\n",
    "    mu2 = F.avg_pool2d(img2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.avg_pool2d(img1 * img1, kernel_size=3, stride=1, padding=1) - mu1_sq\n",
    "    sigma2_sq = F.avg_pool2d(img2 * img2, kernel_size=3, stride=1, padding=1) - mu2_sq\n",
    "    sigma12 = F.avg_pool2d(img1 * img2, kernel_size=3, stride=1, padding=1) - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()\n",
    "\n",
    "# 저해상도 이미지 생성 함수\n",
    "def create_low_res_images(input_dir, output_dir, scale):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "            img = Image.open(os.path.join(input_dir, filename))\n",
    "            lr_img = img.resize((img.width // scale, img.height // scale), Image.BICUBIC)\n",
    "            lr_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "# SRDataset 클래스 정의(학습 데이터DIV2K 사용)\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, hr_dir, lr_dir, transform=None, target_size=(256, 256)):\n",
    "        self.hr_dir = hr_dir\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_filenames = sorted(os.listdir(hr_dir))\n",
    "        self.lr_filenames = sorted(os.listdir(lr_dir))\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hr_path = os.path.join(self.hr_dir, self.hr_filenames[idx])\n",
    "        lr_path = os.path.join(self.lr_dir, self.lr_filenames[idx])\n",
    "\n",
    "        hr_img = Image.open(hr_path).convert(\"RGB\")\n",
    "        lr_img = Image.open(lr_path).convert(\"RGB\")\n",
    "        hr_img = transforms.Resize(self.target_size)(hr_img)\n",
    "        lr_img = transforms.Resize(self.target_size)(lr_img)\n",
    "\n",
    "        if self.transform:\n",
    "            hr_img = self.transform(hr_img)\n",
    "            lr_img = self.transform(lr_img)\n",
    "\n",
    "        return lr_img, hr_img\n",
    "\n",
    "# SRCNN 모델 정의\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "# 데이터 경로\n",
    "train_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_HR\"\n",
    "train_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_train_LR\"\n",
    "valid_hr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_HR\"\n",
    "valid_lr_dir = r\"C:\\Users\\kowm6\\Desktop\\SRdataset\\DIV2K\\DIV2K_valid_LR\"\n",
    "\n",
    "# 데이터셋 및 DataLoader 설정\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = SRDataset(train_hr_dir, train_lr_dir, transform, target_size=(256, 256))\n",
    "valid_dataset = SRDataset(valid_hr_dir, valid_lr_dir, transform, target_size=(256, 256))\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Train\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRCNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "num_epochs = 2\n",
    "best_valid_loss = float('inf')\n",
    "save_path = r\"C:\\Users\\kowm6\\Desktop\\sr\\best_model.pth\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 학습 루프\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_psnr = 0\n",
    "    for lr_imgs, hr_imgs in train_loader:\n",
    "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "        preds = model(lr_imgs)\n",
    "        loss = criterion(preds, hr_imgs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # PSNR 계산\n",
    "        train_psnr += calculate_psnr(preds, hr_imgs)\n",
    "\n",
    "    train_psnr /= len(train_loader)\n",
    "\n",
    "    # 검증 루프\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_psnr = 0\n",
    "    valid_ssim = 0\n",
    "    with torch.no_grad():\n",
    "        for lr_imgs, hr_imgs in valid_loader:\n",
    "            lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "            preds = model(lr_imgs)\n",
    "            valid_loss += criterion(preds, hr_imgs).item()\n",
    "\n",
    "            # PSNR 및 SSIM 계산\n",
    "            valid_psnr += calculate_psnr(preds, hr_imgs)\n",
    "            valid_ssim += calculate_ssim(preds, hr_imgs)\n",
    "\n",
    "    valid_psnr /= len(valid_loader)\n",
    "    valid_ssim /= len(valid_loader)\n",
    "    valid_loss /= len(valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss / len(train_loader):.4f}, \"\n",
    "          f\"Validation Loss: {valid_loss:.4f}, Train PSNR: {train_psnr:.4f}, \"\n",
    "          f\"Validation PSNR: {valid_psnr:.4f}, Validation SSIM: {valid_ssim:.4f}\")\n",
    "\n",
    "    # 최적의 가중치 저장\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"Best model saved!\")\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "test_hr_dir = r\"C:/Users/kowm6/Desktop/testlr\"\n",
    "test_lr_dir = r\"C:/Users/kowm6/Desktop/testhr\"\n",
    "test_dataset = SRDataset(test_hr_dir, test_lr_dir, transform, target_size=(256, 256))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "\n",
    "test_psnr = 0\n",
    "test_ssim = 0\n",
    "num_test_images = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for lr_imgs, hr_imgs in test_loader:\n",
    "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
    "        preds = model(lr_imgs)\n",
    "\n",
    "        test_psnr += calculate_psnr(preds, hr_imgs)\n",
    "        test_ssim += calculate_ssim(preds, hr_imgs)\n",
    "        num_test_images += 1\n",
    "\n",
    "test_psnr /= num_test_images\n",
    "test_ssim /= num_test_images\n",
    "\n",
    "print(f\"Test PSNR: {test_psnr:.4f}, Test SSIM: {test_ssim:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (app)",
   "language": "python",
   "name": "app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
